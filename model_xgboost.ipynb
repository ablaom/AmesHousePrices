{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames House Price Data - Gradient Boosted Trees (XGBoost)\n",
    "\n",
    "> Juptyer notebook, running a Julia 0.5.2 kernel, with the help of Machine Learning modules written by the author\n",
    "\n",
    "*We build an XGBoost model using ?\n",
    "\n",
    "Estimated 95% confidence interval for log-RMS error of Sale Price predictions for the tuned model: \n",
    "\n",
    "    0.145 Â± 0.018\n",
    "\n",
    "## Reading in and transforming  the data\n",
    "Our extreme random forest regressors are constructed in the same way as regular random forests, but with different parameters settings. Once again the input data should be converted to a `TreeCollections.DataTable` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "push!(LOAD_PATH, pwd()) # Allow loading of modules from current directory \n",
    "addprocs(3) # for parallel processing\n",
    "using Regressors, Preprocess, Validation\n",
    "import DataFrames: DataFrame, readtable, writetable\n",
    "import TreeCollections.DataTable\n",
    "\n",
    "df = readtable(\"2.cleaned/train_randomized.csv\")\n",
    "important_features = convert(Array{Symbol}, readtable(\"3.important_features/important_features.csv\")[1])\n",
    "important_features = important_features[1:12]\n",
    "const X = DataTable(df[important_features])\n",
    "const y = collect(df[:target]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
